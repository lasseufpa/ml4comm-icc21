{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "HZ2UfLs0_qU2"
   },
   "source": [
    "This script uses Raymobtime data (https://www.lasse.ufpa.br/raymobtime/) and is based on the code used for the UFPA Problem Statement in the 2020 ITU Artificial Intelligence/Machine Learning in 5G Challenge (http://ai5gchallenge.ufpa.br/).\n",
    "\n",
    "Authors: Ailton Oliveira, Aldebaro Klautau, Arthur Nascimento, Diego Gomes, Jamelly Ferreira, Walter Frazao"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "id": "M2SeKunI_gdX"
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "d:\\Programs\\Anaconda3\\envs\\python36\\lib\\site-packages\\tensorflow\\python\\framework\\dtypes.py:516: FutureWarning: Passing (type, 1) or '1type' as a synonym of type is deprecated; in a future version of numpy, it will be understood as (type, (1,)) / '(1,)type'.\n",
      "  _np_qint8 = np.dtype([(\"qint8\", np.int8, 1)])\n",
      "d:\\Programs\\Anaconda3\\envs\\python36\\lib\\site-packages\\tensorflow\\python\\framework\\dtypes.py:517: FutureWarning: Passing (type, 1) or '1type' as a synonym of type is deprecated; in a future version of numpy, it will be understood as (type, (1,)) / '(1,)type'.\n",
      "  _np_quint8 = np.dtype([(\"quint8\", np.uint8, 1)])\n",
      "d:\\Programs\\Anaconda3\\envs\\python36\\lib\\site-packages\\tensorflow\\python\\framework\\dtypes.py:518: FutureWarning: Passing (type, 1) or '1type' as a synonym of type is deprecated; in a future version of numpy, it will be understood as (type, (1,)) / '(1,)type'.\n",
      "  _np_qint16 = np.dtype([(\"qint16\", np.int16, 1)])\n",
      "d:\\Programs\\Anaconda3\\envs\\python36\\lib\\site-packages\\tensorflow\\python\\framework\\dtypes.py:519: FutureWarning: Passing (type, 1) or '1type' as a synonym of type is deprecated; in a future version of numpy, it will be understood as (type, (1,)) / '(1,)type'.\n",
      "  _np_quint16 = np.dtype([(\"quint16\", np.uint16, 1)])\n",
      "d:\\Programs\\Anaconda3\\envs\\python36\\lib\\site-packages\\tensorflow\\python\\framework\\dtypes.py:520: FutureWarning: Passing (type, 1) or '1type' as a synonym of type is deprecated; in a future version of numpy, it will be understood as (type, (1,)) / '(1,)type'.\n",
      "  _np_qint32 = np.dtype([(\"qint32\", np.int32, 1)])\n",
      "d:\\Programs\\Anaconda3\\envs\\python36\\lib\\site-packages\\tensorflow\\python\\framework\\dtypes.py:525: FutureWarning: Passing (type, 1) or '1type' as a synonym of type is deprecated; in a future version of numpy, it will be understood as (type, (1,)) / '(1,)type'.\n",
      "  np_resource = np.dtype([(\"resource\", np.ubyte, 1)])\n",
      "d:\\Programs\\Anaconda3\\envs\\python36\\lib\\site-packages\\tensorboard\\compat\\tensorflow_stub\\dtypes.py:541: FutureWarning: Passing (type, 1) or '1type' as a synonym of type is deprecated; in a future version of numpy, it will be understood as (type, (1,)) / '(1,)type'.\n",
      "  _np_qint8 = np.dtype([(\"qint8\", np.int8, 1)])\n",
      "d:\\Programs\\Anaconda3\\envs\\python36\\lib\\site-packages\\tensorboard\\compat\\tensorflow_stub\\dtypes.py:542: FutureWarning: Passing (type, 1) or '1type' as a synonym of type is deprecated; in a future version of numpy, it will be understood as (type, (1,)) / '(1,)type'.\n",
      "  _np_quint8 = np.dtype([(\"quint8\", np.uint8, 1)])\n",
      "d:\\Programs\\Anaconda3\\envs\\python36\\lib\\site-packages\\tensorboard\\compat\\tensorflow_stub\\dtypes.py:543: FutureWarning: Passing (type, 1) or '1type' as a synonym of type is deprecated; in a future version of numpy, it will be understood as (type, (1,)) / '(1,)type'.\n",
      "  _np_qint16 = np.dtype([(\"qint16\", np.int16, 1)])\n",
      "d:\\Programs\\Anaconda3\\envs\\python36\\lib\\site-packages\\tensorboard\\compat\\tensorflow_stub\\dtypes.py:544: FutureWarning: Passing (type, 1) or '1type' as a synonym of type is deprecated; in a future version of numpy, it will be understood as (type, (1,)) / '(1,)type'.\n",
      "  _np_quint16 = np.dtype([(\"quint16\", np.uint16, 1)])\n",
      "d:\\Programs\\Anaconda3\\envs\\python36\\lib\\site-packages\\tensorboard\\compat\\tensorflow_stub\\dtypes.py:545: FutureWarning: Passing (type, 1) or '1type' as a synonym of type is deprecated; in a future version of numpy, it will be understood as (type, (1,)) / '(1,)type'.\n",
      "  _np_qint32 = np.dtype([(\"qint32\", np.int32, 1)])\n",
      "d:\\Programs\\Anaconda3\\envs\\python36\\lib\\site-packages\\tensorboard\\compat\\tensorflow_stub\\dtypes.py:550: FutureWarning: Passing (type, 1) or '1type' as a synonym of type is deprecated; in a future version of numpy, it will be understood as (type, (1,)) / '(1,)type'.\n",
      "  np_resource = np.dtype([(\"resource\", np.ubyte, 1)])\n"
     ]
    }
   ],
   "source": [
    "'''\n",
    "Train a deep NN for choosing top-K beams.\n",
    "Note that you need to download the datasets and save them in the folder specified in this code. \n",
    "'''\n",
    "\n",
    "#Import modules\n",
    "import os\n",
    "import csv\n",
    "import argparse\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "import tensorflow as tf\n",
    "from tensorflow.keras import metrics\n",
    "from tensorflow.keras.models import model_from_json,Model\n",
    "from tensorflow.keras.layers import Dense,concatenate\n",
    "from tensorflow.keras.losses import categorical_crossentropy\n",
    "from tensorflow.keras.optimizers import Adadelta,Adam\n",
    "from sklearn.model_selection import train_test_split\n",
    "from ml4comm.model_handler import ModelHandler"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "id": "64sKBpO_Dz7S"
   },
   "outputs": [],
   "source": [
    "#Here you can choose a combination of sets of parameters to be used as the neural network input\n",
    "coord = False  #coordinates with the receiver position obtained from GPS\n",
    "img = False  #RGB images obtained from cameras\n",
    "lidar = True  #three-dimensional histogram obtained form LIDAR point cloud\n",
    "\n",
    "#Based on your choices above, make sure the datasets below can be found in the specific folders.\n",
    "#If running on Colab, you may use /content/\n",
    "COORDINATES_INPUT_FILE = \"./data/coord_input/coord_input.npz\"\n",
    "IMAGES_INPUT_FILE = \"./data/image_input/img_input_20.npz\"\n",
    "LIDAR_INPUT_FILE = \"./data/lidar_input/lidar_input.npz\"\n",
    "BEAM_OUTPUT_FILE = \"./data/beam_output/beams_output.npz\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "id": "yR2f0lT3BD41"
   },
   "outputs": [],
   "source": [
    "###############################################################################\n",
    "# Support functions\n",
    "###############################################################################\n",
    "\n",
    "#For description about top-k, including the explanation on how they treat ties (which can be misleading\n",
    "#if your classifier is outputting a lot of ties (e.g. all 0's will lead to high top-k)\n",
    "#https://www.tensorflow.org/api_docs/python/tf/nn/in_top_k\n",
    "#define top-k accuracy for different values of k\n",
    "def top_10_accuracy(y_true,y_pred):\n",
    "    return metrics.top_k_categorical_accuracy(y_true,y_pred,k=10)\n",
    "\n",
    "def top_30_accuracy(y_true, y_pred):\n",
    "    return metrics.top_k_categorical_accuracy(y_true, y_pred, k=30)\n",
    "\n",
    "def top_50_accuracy(y_true,y_pred):\n",
    "    return metrics.top_k_categorical_accuracy(y_true,y_pred,k=50)\n",
    "\n",
    "def top_100_accuracy(y_true, y_pred):\n",
    "    return metrics.top_k_categorical_accuracy(y_true, y_pred, k=100)\n",
    "\n",
    "#convert pair of indices to a single index\n",
    "def sub2ind(array_shape, rows, cols):\n",
    "    ind = rows*array_shape[1] + cols\n",
    "    ind[ind < 0] = -1\n",
    "    ind[ind >= array_shape[0]*array_shape[1]] = -1\n",
    "    return ind\n",
    "\n",
    "#convert index into a pair of indices\n",
    "def ind2sub(array_shape, ind):\n",
    "    ind[ind < 0] = -1\n",
    "    ind[ind >= array_shape[0]*array_shape[1]] = -1\n",
    "    rows = (ind.astype('int') / array_shape[1])\n",
    "    cols = ind % array_shape[1]\n",
    "    return (rows, cols)\n",
    "\n",
    "#converts to log scale and make zero the values below the specified threshold\n",
    "def beamsLogScale(y,thresholdBelowMax):\n",
    "        y_shape = y.shape\n",
    "        \n",
    "        for i in range(0,y_shape[0]):            \n",
    "            thisOutputs = y[i,:]\n",
    "            logOut = 20*np.log10(thisOutputs + 1e-30)\n",
    "            minValue = np.amax(logOut) - thresholdBelowMax\n",
    "            zeroedValueIndices = logOut < minValue\n",
    "            thisOutputs[zeroedValueIndices]=0\n",
    "            thisOutputs = thisOutputs / sum(thisOutputs)\n",
    "            y[i,:] = thisOutputs\n",
    "        \n",
    "        return y\n",
    "\n",
    "def getBeamOutput(output_file):\n",
    "    \n",
    "    thresholdBelowMax = 60\n",
    "    \n",
    "    print(\"Reading dataset...\", output_file)\n",
    "    output_cache_file = np.load(output_file)\n",
    "    yMatrix = output_cache_file['output_classification']\n",
    "    \n",
    "    yMatrix = np.abs(yMatrix)\n",
    "    yMatrix /= np.max(yMatrix)\n",
    "    yMatrixShape = yMatrix.shape\n",
    "    num_classes = yMatrix.shape[1] * yMatrix.shape[2]\n",
    "    \n",
    "    y = yMatrix.reshape(yMatrix.shape[0],num_classes)\n",
    "    y = beamsLogScale(y,thresholdBelowMax)\n",
    "    \n",
    "    return y,num_classes"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "d51Vk9o4CzSo",
    "outputId": "e46b2848-2ca2-42ee-f9e8-fd0a5bbc2911"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Reading dataset...  ./data/lidar_input/lidar_input.npz\n",
      "Reading dataset... ./data/beam_output/beams_output.npz\n"
     ]
    }
   ],
   "source": [
    "###############################################################################\n",
    "# Data configuration\n",
    "###############################################################################\n",
    "\n",
    "tf.device('/device:GPU:0')\n",
    "\n",
    "num_epochs = 2 #assume a rather small number just to demo things. You should try larger values\n",
    "batch_size = 32\n",
    "tgtRec = 3\n",
    "seed = 7\n",
    "\n",
    "np.random.seed(seed)\n",
    "\n",
    "if coord == True: \n",
    "    #train\n",
    "    coord_train_cache_file = np.load(COORDINATES_INPUT_FILE)\n",
    "    X_coord = coord_train_cache_file['coordinates']\n",
    "    X_coord_train, X_coord_validation = train_test_split(X_coord, test_size=0.2, random_state=seed, shuffle=True)\n",
    "    print(\"Reading dataset... \",COORDINATES_INPUT_FILE)\n",
    "    coord_train_input_shape = X_coord_train.shape\n",
    "\n",
    "if img == True:\n",
    "    resizeFac = 20 # Resize Factor\n",
    "    nCh = 1 # The number of channels of the image\n",
    "    imgDim = (360,640) # Image dimensions\n",
    "    method = 1\n",
    "\n",
    "    #train\n",
    "    img_train_cache_file = np.load(IMAGES_INPUT_FILE)\n",
    "    X_img = img_train_cache_file['inputs']\n",
    "    X_img_train, X_img_validation = train_test_split(X_img, test_size=0.2, random_state=seed, shuffle=True)\n",
    "    print(\"Reading dataset... \",IMAGES_INPUT_FILE)\n",
    "\n",
    "    img_train_input_shape = X_img_train.shape\n",
    "\n",
    "if lidar == True:\n",
    "    #train\n",
    "    lidar_train_cache_file = np.load(LIDAR_INPUT_FILE)\n",
    "    X_lidar = lidar_train_cache_file['input']\n",
    "    X_lidar_train, X_lidar_validation = train_test_split(X_lidar, test_size=0.2, random_state=seed, shuffle=True)\n",
    "    print(\"Reading dataset... \",LIDAR_INPUT_FILE)\n",
    "    lidar_train_input_shape = X_lidar_train.shape\n",
    "\n",
    "###############################################################################\n",
    "# Output configuration\n",
    "#train\n",
    "y_output,num_classes = getBeamOutput(BEAM_OUTPUT_FILE)\n",
    "y_train, y_validation = train_test_split(y_output, test_size=0.2, random_state=seed, shuffle=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[0.00146982 0.00056125 0.00055414 0.00044021 0.00045633 0.00039816\n",
      " 0.00036833 0.00034294 0.00032207 0.0003045  0.00028888 0.00027398\n",
      " 0.00027869 0.00080263 0.00034824 0.00029878 0.00024877 0.00027781\n",
      " 0.00135507 0.00034706 0.00071369 0.         0.00068005 0.00070506\n",
      " 0.00083613 0.0010586  0.00176501 0.00251836 0.00917728 0.00549423\n",
      " 0.00242845 0.0013558  0.0016544  0.00062371 0.0006203  0.00049732\n",
      " 0.00051177 0.00044754 0.00041425 0.00038595 0.00036278 0.00034369\n",
      " 0.00032861 0.00032506 0.00045562 0.00168838 0.00055609 0.00046739\n",
      " 0.00048498 0.00134429 0.00214406 0.00049101 0.0007783  0.\n",
      " 0.0007139  0.00076337 0.00091534 0.00116641 0.00197566 0.00279639\n",
      " 0.01021861 0.00613227 0.00270514 0.00152045 0.00262671 0.00117486\n",
      " 0.00117904 0.00100761 0.00104231 0.00096609 0.0009359  0.00091886\n",
      " 0.0009174  0.0009344  0.00097888 0.00108477 0.00151075 0.00302151\n",
      " 0.00117956 0.00130951 0.00175391 0.00045254 0.00262179 0.02541165\n",
      " 0.00187437 0.00137173 0.         0.00028012 0.00060813 0.00103675\n",
      " 0.00224964 0.00336567 0.01352118 0.00875311 0.00404167 0.00243448\n",
      " 0.00523174 0.0019367  0.00202325 0.00167418 0.00175675 0.00159735\n",
      " 0.00152091 0.00146443 0.00142949 0.00141554 0.00142439 0.0014645\n",
      " 0.0015886  0.00134301 0.00157713 0.00180437 0.00219721 0.00299162\n",
      " 0.01444069 0.00064757 0.00116426 0.00162103 0.00105988 0.00143304\n",
      " 0.00197825 0.00276251 0.00566584 0.00744053 0.02838132 0.01767543\n",
      " 0.00786986 0.00468136 0.05122726 0.01405406 0.00949368 0.00777853\n",
      " 0.00808188 0.00567443 0.00555817 0.00528429 0.00505187 0.00487342\n",
      " 0.00474528 0.00466128 0.0046075  0.00478792 0.00471867 0.00479075\n",
      " 0.00488608 0.00504564 0.00283103 0.00621202 0.00749475 0.0060176\n",
      " 0.00723706 0.00906225 0.01115583 0.01442214 0.02184125 0.03540625\n",
      " 0.13102017 0.08037336 0.02296715 0.02119128 0.00319026 0.00131542\n",
      " 0.00126218 0.00098796 0.0010389  0.00090361 0.00083884 0.00078421\n",
      " 0.00074063 0.00070577 0.00067707 0.00065059 0.00061229 0.00091433\n",
      " 0.00068551 0.00065582 0.00061741 0.00058984 0.00115998 0.00087104\n",
      " 0.00122723 0.00029037 0.00231035 0.00176996 0.00196781 0.00242905\n",
      " 0.00384839 0.0056683  0.02056158 0.01226753 0.00553047 0.0030034\n",
      " 0.00192521 0.0007682  0.00074794 0.00059141 0.00061726 0.00053919\n",
      " 0.00050055 0.00046799 0.00044185 0.00042065 0.00040272 0.00038534\n",
      " 0.00036193 0.00066541 0.0004254  0.00039749 0.00036325 0.00035473\n",
      " 0.00108827 0.00052188 0.00085453 0.         0.0009779  0.00094329\n",
      " 0.00110634 0.00139701 0.002286   0.00332564 0.01213036 0.00726868\n",
      " 0.00324383 0.00179377 0.00154147 0.00060115 0.00058981 0.00046757\n",
      " 0.00048652 0.00042499 0.00039397 0.00036773 0.00034644 0.00032885\n",
      " 0.00031352 0.00029828 0.00028361 0.00064417 0.00034722 0.00031388\n",
      " 0.00027612 0.00027884 0.00113407 0.00039015 0.00071838 0.\n",
      " 0.00073444 0.00074216 0.00087738 0.00111063 0.00183761 0.0026463\n",
      " 0.00965213 0.00578329 0.00256721 0.00142817]\n"
     ]
    }
   ],
   "source": [
    "print(y_output[1,:])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 945
    },
    "id": "bXtxMcdgP5EX",
    "outputId": "09f6ecf4-1ce3-45ec-9337-03358c001716"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "WARNING:tensorflow:From d:\\Programs\\Anaconda3\\envs\\python36\\lib\\site-packages\\tensorflow\\python\\ops\\init_ops.py:1251: calling VarianceScaling.__init__ (from tensorflow.python.ops.init_ops) with dtype is deprecated and will be removed in a future version.\n",
      "Instructions for updating:\n",
      "Call initializer instance with the dtype argument instead of passing it to the constructor\n",
      "Model: \"model\"\n",
      "_________________________________________________________________\n",
      "Layer (type)                 Output Shape              Param #   \n",
      "=================================================================\n",
      "input_1 (InputLayer)         [(None, 20, 200, 10)]     0         \n",
      "_________________________________________________________________\n",
      "conv2d (Conv2D)              (None, 20, 200, 10)       16910     \n",
      "_________________________________________________________________\n",
      "conv2d_1 (Conv2D)            (None, 20, 200, 10)       12110     \n",
      "_________________________________________________________________\n",
      "max_pooling2d (MaxPooling2D) (None, 6, 40, 10)         0         \n",
      "_________________________________________________________________\n",
      "dropout (Dropout)            (None, 6, 40, 10)         0         \n",
      "_________________________________________________________________\n",
      "conv2d_2 (Conv2D)            (None, 6, 40, 10)         4910      \n",
      "_________________________________________________________________\n",
      "max_pooling2d_1 (MaxPooling2 (None, 6, 20, 10)         0         \n",
      "_________________________________________________________________\n",
      "dropout_1 (Dropout)          (None, 6, 20, 10)         0         \n",
      "_________________________________________________________________\n",
      "conv2d_3 (Conv2D)            (None, 6, 20, 10)         910       \n",
      "_________________________________________________________________\n",
      "max_pooling2d_2 (MaxPooling2 (None, 6, 10, 10)         0         \n",
      "_________________________________________________________________\n",
      "dropout_2 (Dropout)          (None, 6, 10, 10)         0         \n",
      "_________________________________________________________________\n",
      "flatten (Flatten)            (None, 600)               0         \n",
      "_________________________________________________________________\n",
      "dense (Dense)                (None, 256)               153856    \n",
      "=================================================================\n",
      "Total params: 188,696\n",
      "Trainable params: 188,696\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n",
      "Train on 8955 samples, validate on 2239 samples\n",
      "Epoch 1/2\n",
      "8955/8955 [==============================] - 215s 24ms/sample - loss: 4.9015 - categorical_accuracy: 0.2009 - top_k_categorical_accuracy: 0.5465 - top_10_accuracy: 0.7013 - top_30_accuracy: 0.9003 - top_50_accuracy: 0.9451 - top_100_accuracy: 0.9805 - val_loss: 4.8132 - val_categorical_accuracy: 0.2890 - val_top_k_categorical_accuracy: 0.6324 - val_top_10_accuracy: 0.7655 - val_top_30_accuracy: 0.9375 - val_top_50_accuracy: 0.9652 - val_top_100_accuracy: 0.9870\n",
      "Epoch 2/2\n",
      "8544/8955 [===========================>..] - ETA: 9s - loss: 4.7637 - categorical_accuracy: 0.2822 - top_k_categorical_accuracy: 0.6703 - top_10_accuracy: 0.8011 - top_30_accuracy: 0.9505 - top_50_accuracy: 0.9732 - top_100_accuracy: 0.9920"
     ]
    }
   ],
   "source": [
    "##############################################################################\n",
    "# Model configuration\n",
    "##############################################################################\n",
    "\n",
    "#multimodal\n",
    "multimodal = [coord, img, lidar]\n",
    "plot = True # Active Plot output\n",
    "\n",
    "#validationFraction = 0.2 #from 0 to 1\n",
    "modelHandler = ModelHandler() #this class create some DNN models\n",
    "opt = Adam() #optimizer\n",
    "\n",
    "if coord:\n",
    "    coord_model = modelHandler.createArchitecture('coord_mlp',num_classes,coord_train_input_shape[1],'complete')\n",
    "if img:\n",
    "    if nCh==1:   \n",
    "        img_model = modelHandler.createArchitecture('light_image',num_classes,[img_train_input_shape[1],img_train_input_shape[2],1],'complete')\n",
    "    else:\n",
    "        img_model = modelHandler.createArchitecture('light_image',num_classes,[img_train_input_shape[1],img_train_input_shape[2],img_train_input_shape[3]],'complete')\n",
    "if lidar:\n",
    "    lidar_model = modelHandler.createArchitecture('lidar_simple',num_classes,[lidar_train_input_shape[1],lidar_train_input_shape[2],lidar_train_input_shape[3]],'complete')\n",
    "\n",
    "if sum(multimodal) == 2:\n",
    "    if coord and lidar:\n",
    "        combined_model = concatenate([coord_model.output,lidar_model.output])\n",
    "        z = Dense(num_classes,activation=\"relu\")(combined_model)\n",
    "        model = Model(inputs=[coord_model.input,lidar_model.input],outputs=z)\n",
    "        model.compile(loss=categorical_crossentropy,\n",
    "                    optimizer=opt,\n",
    "                    metrics=[metrics.categorical_accuracy,\n",
    "                            metrics.top_k_categorical_accuracy,\n",
    "                            top_10_accuracy,\n",
    "                            top_30_accuracy,\n",
    "                            top_50_accuracy,\n",
    "                            top_100_accuracy])\n",
    "        model.summary()\n",
    "        hist = model.fit([X_coord_train,X_lidar_train],y_train, \n",
    "        validation_data=([X_coord_validation, X_lidar_validation], y_validation),epochs=num_epochs,batch_size=batch_size)\n",
    "\n",
    "    elif coord and img:\n",
    "        combined_model = concatenate([coord_model.output,img_model.output])\n",
    "        z = Dense(num_classes,activation=\"relu\")(combined_model)\n",
    "        model = Model(inputs=[coord_model.input,img_model.input],outputs=z)\n",
    "        model.compile(loss=categorical_crossentropy,\n",
    "                    optimizer=opt,\n",
    "                    metrics=[metrics.categorical_accuracy,\n",
    "                            metrics.top_k_categorical_accuracy,\n",
    "                            top_10_accuracy,\n",
    "                            top_30_accuracy,\n",
    "                            top_50_accuracy,\n",
    "                            top_100_accuracy])\n",
    "        model.summary()\n",
    "        hist = model.fit([X_coord_train,X_img_train],y_train,\n",
    "        validation_data=([X_coord_validation, X_img_validation], y_validation), epochs=num_epochs,batch_size=batch_size)\n",
    "    \n",
    "    else:\n",
    "        combined_model = concatenate([lidar_model.output,img_model.output])\n",
    "        z = Dense(num_classes,activation=\"relu\")(combined_model)\n",
    "        model = Model(inputs=[lidar_model.input,img_model.input],outputs=z)\n",
    "        model.compile(loss=categorical_crossentropy,\n",
    "                    optimizer=opt,\n",
    "                    metrics=[metrics.categorical_accuracy,\n",
    "                            metrics.top_k_categorical_accuracy,\n",
    "                            top_10_accuracy,\n",
    "                            top_30_accuracy,\n",
    "                            top_50_accuracy,\n",
    "                            top_100_accuracy])\n",
    "        model.summary()\n",
    "        hist = model.fit([X_lidar_train,X_img_train],y_train, \n",
    "        validation_data=([X_lidar_validation, X_img_validation], y_validation), epochs=num_epochs,batch_size=batch_size)\n",
    "\n",
    "elif sum(multimodal) == 3:\n",
    "    combined_model = concatenate([lidar_model.output,img_model.output, coord_model.output])\n",
    "    z = Dense(num_classes,activation=\"relu\")(combined_model)\n",
    "    model = Model(inputs=[lidar_model.input,img_model.input, coord_model.input],outputs=z)\n",
    "    model.compile(loss=categorical_crossentropy,\n",
    "                optimizer=opt,\n",
    "                metrics=[metrics.categorical_accuracy,\n",
    "                        metrics.top_k_categorical_accuracy,\n",
    "                        top_10_accuracy,\n",
    "                        top_30_accuracy,\n",
    "                        top_50_accuracy,\n",
    "                        top_100_accuracy])\n",
    "    model.summary()\n",
    "    hist = model.fit([X_lidar_train,X_img_train,X_coord_train],y_train,\n",
    "            validation_data=([X_lidar_validation, X_img_validation, X_coord_validation], y_validation),\n",
    "            epochs=num_epochs,batch_size=batch_size)\n",
    "\n",
    "else:\n",
    "    if coord:\n",
    "        model = coord_model\n",
    "        model.compile(loss=categorical_crossentropy,\n",
    "                            optimizer=opt,\n",
    "                            metrics=[metrics.categorical_accuracy,\n",
    "                                    metrics.top_k_categorical_accuracy,\n",
    "                                    top_10_accuracy,\n",
    "                                    top_30_accuracy, \n",
    "                                    top_50_accuracy,\n",
    "                                    top_100_accuracy])\n",
    "        model.summary()\n",
    "        hist = model.fit(X_coord_train,y_train, \n",
    "        validation_data=(X_coord_validation, y_validation),epochs=num_epochs,batch_size=batch_size)\n",
    "\n",
    "    elif img:\n",
    "        model = img_model  \n",
    "        model.compile(loss=categorical_crossentropy,\n",
    "                    optimizer=opt,\n",
    "                    metrics=[metrics.categorical_accuracy,\n",
    "                            metrics.top_k_categorical_accuracy,\n",
    "                            top_10_accuracy,\n",
    "                            top_30_accuracy,\n",
    "                            top_50_accuracy,\n",
    "                            top_100_accuracy])\n",
    "        model.summary()\n",
    "        hist = model.fit(X_img_train,y_train, \n",
    "        validation_data=(X_img_validation, y_validation),epochs=num_epochs,batch_size=batch_size)\n",
    "\n",
    "    else:\n",
    "        model = lidar_model\n",
    "        model.compile(loss=categorical_crossentropy,\n",
    "                    optimizer=opt,\n",
    "                    metrics=[metrics.categorical_accuracy,\n",
    "                            metrics.top_k_categorical_accuracy,\n",
    "                            top_10_accuracy,\n",
    "                            top_30_accuracy,\n",
    "                            top_50_accuracy,\n",
    "                            top_100_accuracy])\n",
    "        model.summary()\n",
    "        hist = model.fit(X_lidar_train,y_train,epochs=num_epochs,batch_size=batch_size, validation_data=(X_lidar_validation, y_validation))\n",
    "\n",
    "with open('history.txt', 'w') as f: \n",
    "       f.write(str(hist.history))\n",
    "\n",
    "if plot:\n",
    "       k_beams = [1, 5, 10, 30, 50]\n",
    "       fig, ax = plt.subplots(figsize=(7,4))\n",
    "       # acurracy's\n",
    "       y = [max(hist.history['categorical_accuracy']),\n",
    "       max(hist.history['top_k_categorical_accuracy']),\n",
    "       max(hist.history['top_10_accuracy']),\n",
    "       max(hist.history['top_30_accuracy']),\n",
    "       max(hist.history['top_50_accuracy'])]\n",
    "       ax.plot(k_beams,y, 'r--s', label = 'Beam selection accuracy')\n",
    "       # original labels\n",
    "       '''ax.plot(k_beams,y_ori, 'b--s', label = 'Correct orientation-LIDAR')\n",
    "       ax.plot(k_beams,y_sori, 'k--s', label = 'Fixed oientation-LIDAR ')\n",
    "       ax.plot(k_beams,y_MM_ori, 'm--s', label = 'Correct orientation-MM')\n",
    "       ax.plot(k_beams,y_MM_sori, 'r--s', label = 'Fixed oientation-MM')'''\n",
    "       ax.set(xlabel='Top K', ylabel='Accuracy')\n",
    "       plt.xlim(right=51)\n",
    "       ax.grid()\n",
    "       plt.legend()\n",
    "       plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "owJTCe03bK08"
   },
   "source": [
    "## **Accuracy / epochs**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 279
    },
    "id": "wiwCaFRsbIqE",
    "outputId": "dd017573-11ba-41fe-e5f4-d51f5ed2ba7b"
   },
   "outputs": [],
   "source": [
    "fig, ax = plt.subplots(figsize=(7,4))\n",
    "ax.plot(hist.history['categorical_accuracy'], 'b', label = 'Categorical accuracy', linewidth=2)\n",
    "ax.plot(hist.history['top_k_categorical_accuracy'], 'k--', label = 'Top 5', linewidth=2)\n",
    "ax.plot(hist.history['top_10_accuracy'], 'm', label = 'Top 10', linewidth=2)\n",
    "ax.plot(hist.history['top_30_accuracy'], 'g--', label = 'Top 30', linewidth=2)\n",
    "ax.plot(hist.history['top_50_accuracy'], 'r', label = 'Top 50', linewidth=2)\n",
    "ax.set(xlabel='Epochs', ylabel='Accuracy')\n",
    "ax.grid()\n",
    "plt.legend()\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "CPQdzsj9cHTa"
   },
   "source": [
    "## **Accuracy / Top k**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "ClYK6VMFb99a"
   },
   "outputs": [],
   "source": [
    "def top_n_Rt(y_predict,valid_, N = 1):\n",
    "    predict = y_predict[:,:N]\n",
    "    original= valid_[:,-N:]\n",
    "    rt = np.sum(1+predict) / np.sum(1+original)\n",
    "    return rt"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 279
    },
    "id": "_0WkXun2bjnL",
    "outputId": "bec27a82-dde7-4664-89c1-e9730bc8d8c8"
   },
   "outputs": [],
   "source": [
    "y_predict = model.predict(X_lidar_validation)\n",
    "valid_ = np.sort(y_validation)\n",
    "\n",
    "y = [max(hist.history['categorical_accuracy']),\n",
    "     max(hist.history['top_k_categorical_accuracy']),\n",
    "     max(hist.history['top_10_accuracy']),\n",
    "     max(hist.history['top_30_accuracy']),\n",
    "     max(hist.history['top_50_accuracy'])]\n",
    "y_rt=[]\n",
    "k_beams = [1, 5, 10, 30, 50]\n",
    "for i in k_beams:\n",
    "    rt = top_n_Rt(y_predict,valid_,i)\n",
    "    y_rt.append(rt)\n",
    "fig, ax = plt.subplots(figsize=(7,4))\n",
    "ax.plot(k_beams,y_rt, 'b', label = 'Throughput ratio')\n",
    "ax.plot(k_beams,y, 'r', label = 'Beam selection accuracy')\n",
    "ax.set(xlabel='Top K', ylabel='Accuracy')\n",
    "plt.xlim(right=51)\n",
    "ax.grid()\n",
    "plt.legend()\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "DhQQrS7lcT4b"
   },
   "source": [
    "## **Throughput ratio**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 279
    },
    "id": "BLIiYvAFbyl4",
    "outputId": "c8ff4606-60a3-4384-fb1c-a1b1b7d31fd9"
   },
   "outputs": [],
   "source": [
    "y_predict = model.predict(X_lidar_validation)\n",
    "valid_ = np.sort(y_validation)\n",
    "examples = valid_.shape[0]\n",
    "y=[]\n",
    "for i in range(examples):\n",
    "    rt = top_n_Rt(y_predict,valid_,i)\n",
    "    y.append(rt)\n",
    "fig, ax = plt.subplots(figsize=(7,4))\n",
    "ax.plot(y[:], 'b--', label = 'Throughput ratio')\n",
    "ax.set(xlabel='Top K', ylabel='Accuracy')\n",
    "ax.grid()\n",
    "plt.legend()\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "DBzpG1qMcjJD"
   },
   "source": [
    "## **Save output**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "wNY2M_LVb4Pi"
   },
   "outputs": [],
   "source": [
    "fileNameIdentifier = 'training_history'\n",
    "f = open(fileNameIdentifier + '.txt','w')\n",
    "f.write(str(hist.history))\n",
    "f.close()"
   ]
  }
 ],
 "metadata": {
  "colab": {
   "name": "beam_selection.ipynb",
   "provenance": []
  },
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.10"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 1
}
