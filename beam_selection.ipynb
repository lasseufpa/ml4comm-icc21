{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "id": "E0NlguFa_iSe"
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "d:\\Programs\\Anaconda3\\envs\\python36\\lib\\site-packages\\tensorflow\\python\\framework\\dtypes.py:516: FutureWarning: Passing (type, 1) or '1type' as a synonym of type is deprecated; in a future version of numpy, it will be understood as (type, (1,)) / '(1,)type'.\n",
      "  _np_qint8 = np.dtype([(\"qint8\", np.int8, 1)])\n",
      "d:\\Programs\\Anaconda3\\envs\\python36\\lib\\site-packages\\tensorflow\\python\\framework\\dtypes.py:517: FutureWarning: Passing (type, 1) or '1type' as a synonym of type is deprecated; in a future version of numpy, it will be understood as (type, (1,)) / '(1,)type'.\n",
      "  _np_quint8 = np.dtype([(\"quint8\", np.uint8, 1)])\n",
      "d:\\Programs\\Anaconda3\\envs\\python36\\lib\\site-packages\\tensorflow\\python\\framework\\dtypes.py:518: FutureWarning: Passing (type, 1) or '1type' as a synonym of type is deprecated; in a future version of numpy, it will be understood as (type, (1,)) / '(1,)type'.\n",
      "  _np_qint16 = np.dtype([(\"qint16\", np.int16, 1)])\n",
      "d:\\Programs\\Anaconda3\\envs\\python36\\lib\\site-packages\\tensorflow\\python\\framework\\dtypes.py:519: FutureWarning: Passing (type, 1) or '1type' as a synonym of type is deprecated; in a future version of numpy, it will be understood as (type, (1,)) / '(1,)type'.\n",
      "  _np_quint16 = np.dtype([(\"quint16\", np.uint16, 1)])\n",
      "d:\\Programs\\Anaconda3\\envs\\python36\\lib\\site-packages\\tensorflow\\python\\framework\\dtypes.py:520: FutureWarning: Passing (type, 1) or '1type' as a synonym of type is deprecated; in a future version of numpy, it will be understood as (type, (1,)) / '(1,)type'.\n",
      "  _np_qint32 = np.dtype([(\"qint32\", np.int32, 1)])\n",
      "d:\\Programs\\Anaconda3\\envs\\python36\\lib\\site-packages\\tensorflow\\python\\framework\\dtypes.py:525: FutureWarning: Passing (type, 1) or '1type' as a synonym of type is deprecated; in a future version of numpy, it will be understood as (type, (1,)) / '(1,)type'.\n",
      "  np_resource = np.dtype([(\"resource\", np.ubyte, 1)])\n",
      "d:\\Programs\\Anaconda3\\envs\\python36\\lib\\site-packages\\tensorboard\\compat\\tensorflow_stub\\dtypes.py:541: FutureWarning: Passing (type, 1) or '1type' as a synonym of type is deprecated; in a future version of numpy, it will be understood as (type, (1,)) / '(1,)type'.\n",
      "  _np_qint8 = np.dtype([(\"qint8\", np.int8, 1)])\n",
      "d:\\Programs\\Anaconda3\\envs\\python36\\lib\\site-packages\\tensorboard\\compat\\tensorflow_stub\\dtypes.py:542: FutureWarning: Passing (type, 1) or '1type' as a synonym of type is deprecated; in a future version of numpy, it will be understood as (type, (1,)) / '(1,)type'.\n",
      "  _np_quint8 = np.dtype([(\"quint8\", np.uint8, 1)])\n",
      "d:\\Programs\\Anaconda3\\envs\\python36\\lib\\site-packages\\tensorboard\\compat\\tensorflow_stub\\dtypes.py:543: FutureWarning: Passing (type, 1) or '1type' as a synonym of type is deprecated; in a future version of numpy, it will be understood as (type, (1,)) / '(1,)type'.\n",
      "  _np_qint16 = np.dtype([(\"qint16\", np.int16, 1)])\n",
      "d:\\Programs\\Anaconda3\\envs\\python36\\lib\\site-packages\\tensorboard\\compat\\tensorflow_stub\\dtypes.py:544: FutureWarning: Passing (type, 1) or '1type' as a synonym of type is deprecated; in a future version of numpy, it will be understood as (type, (1,)) / '(1,)type'.\n",
      "  _np_quint16 = np.dtype([(\"quint16\", np.uint16, 1)])\n",
      "d:\\Programs\\Anaconda3\\envs\\python36\\lib\\site-packages\\tensorboard\\compat\\tensorflow_stub\\dtypes.py:545: FutureWarning: Passing (type, 1) or '1type' as a synonym of type is deprecated; in a future version of numpy, it will be understood as (type, (1,)) / '(1,)type'.\n",
      "  _np_qint32 = np.dtype([(\"qint32\", np.int32, 1)])\n",
      "d:\\Programs\\Anaconda3\\envs\\python36\\lib\\site-packages\\tensorboard\\compat\\tensorflow_stub\\dtypes.py:550: FutureWarning: Passing (type, 1) or '1type' as a synonym of type is deprecated; in a future version of numpy, it will be understood as (type, (1,)) / '(1,)type'.\n",
      "  np_resource = np.dtype([(\"resource\", np.ubyte, 1)])\n",
      "usage: ipykernel_launcher.py [-h]\n",
      "                             [--input [{img,coord,lidar} [{img,coord,lidar} ...]]]\n",
      "                             [-p]\n",
      "                             data_folder\n",
      "ipykernel_launcher.py: error: unrecognized arguments: -f\n"
     ]
    },
    {
     "ename": "SystemExit",
     "evalue": "2",
     "output_type": "error",
     "traceback": [
      "An exception has occurred, use %tb to see the full traceback.\n",
      "\u001b[1;31mSystemExit\u001b[0m\u001b[1;31m:\u001b[0m 2\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "d:\\Programs\\Anaconda3\\envs\\python36\\lib\\site-packages\\IPython\\core\\interactiveshell.py:3351: UserWarning: To exit: use 'exit', 'quit', or Ctrl-D.\n",
      "  warn(\"To exit: use 'exit', 'quit', or Ctrl-D.\", stacklevel=1)\n"
     ]
    }
   ],
   "source": [
    "#Script context use\t: This script uses Raymotime data (https://www.lasse.ufpa.br/raymobtime/) in the context of the UFPA - ITU Artificial Intelligence/Machine Learning in 5G Challenge (http://ai5gchallenge.ufpa.br/).\n",
    "#Author       \t\t: Ailton Oliveira, Aldebaro Klautau, Arthur Nascimento, Diego Gomes, Jamelly Ferreira, Walter Frazao\n",
    "#Email          \t: ml5gphy@gmail.com                                          \n",
    "#License\t\t: This script is distributed under \"Public Domain\" license.\n",
    "###################################################################\n",
    "\n",
    "#!/usr/bin/env python3\n",
    "# -*- coding: utf-8 -*-\n",
    "\n",
    "'''Trains a deep NN for choosing top-K beams\n",
    "Adapted by AK: Aug 7, 2018\n",
    "See\n",
    "https://machinelearningmastery.com/binary-classification-tutorial-with-the-keras-deep-learning-library/\n",
    "and\n",
    "https://stackoverflow.com/questions/45642077/do-i-need-to-use-one-hot-encoding-if-my-output-variable-is-binary\n",
    "See for explanation about convnet and filters:\n",
    "https://datascience.stackexchange.com/questions/16463/what-is-are-the-default-filters-used-by-keras-convolution2d\n",
    "and\n",
    "http://cs231n.github.io/convolutional-networks/\n",
    "'''\n",
    "import csv\n",
    "import tensorflow as tf\n",
    "from tensorflow.keras import metrics\n",
    "from tensorflow.keras.models import model_from_json,Model\n",
    "from tensorflow.keras.layers import Dense,concatenate\n",
    "from tensorflow.keras.losses import categorical_crossentropy\n",
    "from tensorflow.keras.optimizers import Adadelta,Adam\n",
    "from sklearn.model_selection import train_test_split\n",
    "from ml4comm_model_handler import ModelHandler\n",
    "import numpy as np\n",
    "import argparse\n",
    "\n",
    "\n",
    "###############################################################################\n",
    "# Support functions\n",
    "###############################################################################\n",
    "\n",
    "#For description about top-k, including the explanation on how they treat ties (which can be misleading\n",
    "#if your classifier is outputting a lot of ties (e.g. all 0's will lead to high top-k)\n",
    "#https://www.tensorflow.org/api_docs/python/tf/nn/in_top_k\n",
    "def top_10_accuracy(y_true,y_pred):\n",
    "    return metrics.top_k_categorical_accuracy(y_true,y_pred,k=10)\n",
    "\n",
    "def top_30_accuracy(y_true, y_pred):\n",
    "    return metrics.top_k_categorical_accuracy(y_true, y_pred, k=30)\n",
    "\n",
    "def top_50_accuracy(y_true,y_pred):\n",
    "    return metrics.top_k_categorical_accuracy(y_true,y_pred,k=50)\n",
    "\n",
    "def top_100_accuracy(y_true, y_pred):\n",
    "    return metrics.top_k_categorical_accuracy(y_true, y_pred, k=100)\n",
    "\n",
    "\n",
    "def sub2ind(array_shape, rows, cols):\n",
    "    ind = rows*array_shape[1] + cols\n",
    "    ind[ind < 0] = -1\n",
    "    ind[ind >= array_shape[0]*array_shape[1]] = -1\n",
    "    return ind\n",
    "\n",
    "def ind2sub(array_shape, ind):\n",
    "    ind[ind < 0] = -1\n",
    "    ind[ind >= array_shape[0]*array_shape[1]] = -1\n",
    "    rows = (ind.astype('int') / array_shape[1])\n",
    "    cols = ind % array_shape[1]\n",
    "    return (rows, cols)\n",
    "\n",
    "def beamsLogScale(y,thresholdBelowMax):\n",
    "        y_shape = y.shape\n",
    "        \n",
    "        for i in range(0,y_shape[0]):            \n",
    "            thisOutputs = y[i,:]\n",
    "            logOut = 20*np.log10(thisOutputs + 1e-30)\n",
    "            minValue = np.amax(logOut) - thresholdBelowMax\n",
    "            zeroedValueIndices = logOut < minValue\n",
    "            thisOutputs[zeroedValueIndices]=0\n",
    "            thisOutputs = thisOutputs / sum(thisOutputs)\n",
    "            y[i,:] = thisOutputs\n",
    "        \n",
    "        return y\n",
    "\n",
    "def getBeamOutput(output_file):\n",
    "    \n",
    "    thresholdBelowMax = 6\n",
    "    \n",
    "    print(\"Reading dataset...\", output_file)\n",
    "    output_cache_file = np.load(output_file)\n",
    "    yMatrix = output_cache_file['output_classification']\n",
    "    \n",
    "    yMatrix = np.abs(yMatrix)\n",
    "    yMatrix /= np.max(yMatrix)\n",
    "    yMatrixShape = yMatrix.shape\n",
    "    num_classes = yMatrix.shape[1] * yMatrix.shape[2]\n",
    "    \n",
    "    y = yMatrix.reshape(yMatrix.shape[0],num_classes)\n",
    "    y = beamsLogScale(y,thresholdBelowMax)\n",
    "    \n",
    "    return y,num_classes\n",
    "\n",
    "if __name__ == '__main__':\n",
    "    parser = argparse.ArgumentParser(description='Configure the files before training the net.')\n",
    "    parser.add_argument('data_folder', help='Location of the data directory', type=str)\n",
    "    #TODO: limit the number of input to 3\n",
    "    parser.add_argument('--input', nargs='*', default=['coord'], \n",
    "    choices = ['img', 'coord', 'lidar'],\n",
    "    help='Which data to use as input. Select from: img, lidar or coord.')\n",
    "    parser.add_argument('-p','--plots', \n",
    "    help='Use this parametter if you want to see the accuracy and loss plots',\n",
    "    action='store_true')\n",
    "    args = parser.parse_args()\n",
    "else:\n",
    "    import sys\n",
    "    sys.path.append('../submission_baseline_example/')\n",
    "    import common\n",
    "    args = common.args\n",
    "\n",
    "###############################################################################\n",
    "# Data configuration\n",
    "###############################################################################\n",
    "tf.device('/device:GPU:0')\n",
    "data_dir = args.data_folder+'/'\n",
    "tgtRec = 3\n",
    "seed = 7\n",
    "np.random.seed(seed)\n",
    "\n",
    "if 'coord' in args.input: \n",
    "    ###############################################################################\n",
    "    # Coordinate configuration\n",
    "    #train\n",
    "    #coord_train_input_file = data_dir+'coord_input/coord_train.npz'\n",
    "    coord_train_input_file = '/content/drive/MyDrive/ssp_data/baseline_data/coord_input/coord_input.npz'\n",
    "    coord_train_cache_file = np.load(coord_train_input_file)\n",
    "    X_coord = coord_train_cache_file['coordinates']\n",
    "    X_coord_train, X_coord_validation = train_test_split(X_coord, test_size=0.2, random_state=seed, shuffle=True)\n",
    "    #validation\n",
    "    #coord_validation_input_file = data_dir+'coord_input/coord_validation.npz'\n",
    "    #coord_validation_cache_file = np.load(coord_validation_input_file)\n",
    "    #X_coord_validation = coord_validation_cache_file['coordinates']\n",
    "\n",
    "    coord_train_input_shape = X_coord_train.shape\n",
    "\n",
    "if 'img' in args.input:\n",
    "    ###############################################################################\n",
    "    # Image configuration\n",
    "    resizeFac = 20 # Resize Factor\n",
    "    nCh = 1 # The number of channels of the image\n",
    "    imgDim = (360,640) # Image dimensions\n",
    "    method = 1\n",
    "    #train\n",
    "    img_train_input_file = '/content/drive/MyDrive/ssp_data/baseline_data/image_input/img_input_20.npz'\n",
    "    img_train_cache_file = np.load(img_train_input_file)\n",
    "    X_img = img_train_cache_file['inputs']\n",
    "    X_img_train, X_img_validation = train_test_split(X_img, test_size=0.2, random_state=seed, shuffle=True)\n",
    "    print(\"Reading dataset... \",img_train_input_file)\n",
    "    #img_train_cache_file = np.load(img_train_input_file)\n",
    "    #X_img_train = img_train_cache_file['inputs']\n",
    "    #validation\n",
    "    #img_validation_input_file = data_dir+'image_input/img_input_validation_'+str(resizeFac)+'.npz'\n",
    "    #print(\"Reading dataset... \",img_validation_input_file)\n",
    "    #img_validation_cache_file = np.load(img_validation_input_file)\n",
    "    #X_img_validation = img_validation_cache_file['inputs']\n",
    "\n",
    "    img_train_input_shape = X_img_train.shape\n",
    "\n",
    "if 'lidar' in args.input:\n",
    "    ###############################################################################\n",
    "    # LIDAR configuration\n",
    "    #train\n",
    "    #lidar_train_input_file = data_dir+'image_input/img_input_train_'+str(resizeFac)+'.npz'\n",
    "    lidar_train_input_file = '/content/drive/MyDrive/ssp_data/baseline_data/lidar_input/lidar_input.npz'\n",
    "    lidar_train_cache_file = np.load(lidar_train_input_file)\n",
    "    X_lidar = lidar_train_cache_file['input']\n",
    "    X_lidar_train, X_lidar_validation = train_test_split(X_lidar, test_size=0.2, random_state=seed, shuffle=True)\n",
    "    print(\"Reading dataset... \",lidar_train_input_file)\n",
    "    '''lidar_train_cache_file = np.load(lidar_train_input_file)\n",
    "    X_lidar_train = lidar_train_cache_file['input']\n",
    "    #validation\n",
    "    lidar_validation_input_file = data_dir+'lidar_input/lidar_validation.npz'\n",
    "    print(\"Reading dataset... \",lidar_validation_input_file)\n",
    "    lidar_validation_cache_file = np.load(lidar_validation_input_file)\n",
    "    X_lidar_validation = lidar_validation_cache_file['input']'''\n",
    "\n",
    "    lidar_train_input_shape = X_lidar_train.shape\n",
    "\n",
    "###############################################################################\n",
    "# Output configuration\n",
    "#train\n",
    "output_file = '/content/drive/MyDrive/ssp_data/baseline_data/beam_output/beams_output.npz'\n",
    "y_output,num_classes = getBeamOutput(output_file)\n",
    "y_train, y_validation = train_test_split(y_output, test_size=0.2, random_state=seed, shuffle=True)\n",
    "#output_validation_file = data_dir+'beam_output/beams_output_validation.npz'\n",
    "#y_validation, _ = getBeamOutput(output_validation_file)\n",
    "\n",
    "##############################################################################\n",
    "# Model configuration\n",
    "##############################################################################\n",
    "\n",
    "#multimodal\n",
    "multimodal = False if len(args.input) == 1 else len(args.input)\n",
    "\n",
    "num_epochs = 3\n",
    "batch_size = 32\n",
    "validationFraction = 0.2 #from 0 to 1\n",
    "modelHand = ModelHandler()\n",
    "opt = Adam()\n",
    "\n",
    "if 'coord' in args.input:\n",
    "    coord_model = modelHand.createArchitecture('coord_mlp',num_classes,coord_train_input_shape[1],'complete')\n",
    "if 'img' in args.input:\n",
    "    num_epochs = 5\n",
    "    if nCh==1:   \n",
    "        img_model = modelHand.createArchitecture('light_image',num_classes,[img_train_input_shape[1],img_train_input_shape[2],1],'complete')\n",
    "    else:\n",
    "        img_model = modelHand.createArchitecture('light_image',num_classes,[img_train_input_shape[1],img_train_input_shape[2],img_train_input_shape[3]],'complete')\n",
    "if 'lidar' in args.input:\n",
    "    lidar_model = modelHand.createArchitecture('lidar_marcus',num_classes,[lidar_train_input_shape[1],lidar_train_input_shape[2],lidar_train_input_shape[3]],'complete')\n",
    "\n",
    "if multimodal == 2:\n",
    "    if 'coord' in args.input and 'lidar' in args.input:\n",
    "        combined_model = concatenate([coord_model.output,lidar_model.output])\n",
    "        z = Dense(num_classes,activation=\"relu\")(combined_model)\n",
    "        model = Model(inputs=[coord_model.input,lidar_model.input],outputs=z)\n",
    "        model.compile(loss=categorical_crossentropy,\n",
    "                    optimizer=opt,\n",
    "                    metrics=[metrics.categorical_accuracy,\n",
    "                            metrics.top_k_categorical_accuracy,\n",
    "                            top_50_accuracy])\n",
    "        model.summary()\n",
    "        hist = model.fit([X_coord_train,X_lidar_train],y_train, \n",
    "        validation_data=([X_coord_validation, X_lidar_validation], y_validation),epochs=num_epochs,batch_size=batch_size)\n",
    "\n",
    "    elif 'coord' in args.input and 'img' in args.input:\n",
    "        combined_model = concatenate([coord_model.output,img_model.output])\n",
    "        z = Dense(num_classes,activation=\"relu\")(combined_model)\n",
    "        model = Model(inputs=[coord_model.input,img_model.input],outputs=z)\n",
    "        model.compile(loss=categorical_crossentropy,\n",
    "                    optimizer=opt,\n",
    "                    metrics=[metrics.categorical_accuracy,\n",
    "                            metrics.top_k_categorical_accuracy,\n",
    "                            top_50_accuracy])\n",
    "        model.summary()\n",
    "        hist = model.fit([X_coord_train,X_img_train],y_train,\n",
    "        validation_data=([X_coord_validation, X_img_validation], y_validation), epochs=num_epochs,batch_size=batch_size)\n",
    "    \n",
    "    else:\n",
    "        combined_model = concatenate([lidar_model.output,img_model.output])\n",
    "        z = Dense(num_classes,activation=\"relu\")(combined_model)\n",
    "        model = Model(inputs=[lidar_model.input,img_model.input],outputs=z)\n",
    "        model.compile(loss=categorical_crossentropy,\n",
    "                    optimizer=opt,\n",
    "                    metrics=[metrics.categorical_accuracy,\n",
    "                            metrics.top_k_categorical_accuracy,\n",
    "                            top_50_accuracy])\n",
    "        model.summary()\n",
    "        hist = model.fit([X_lidar_train,X_img_train],y_train, \n",
    "        validation_data=([X_lidar_validation, X_img_validation], y_validation), epochs=num_epochs,batch_size=batch_size)\n",
    "elif multimodal == 3:\n",
    "    combined_model = concatenate([lidar_model.output,img_model.output, coord_model.output])\n",
    "    z = Dense(num_classes,activation=\"relu\")(combined_model)\n",
    "    model = Model(inputs=[lidar_model.input,img_model.input, coord_model.input],outputs=z)\n",
    "    model.compile(loss=categorical_crossentropy,\n",
    "                optimizer=opt,\n",
    "                metrics=[metrics.categorical_accuracy,\n",
    "                        metrics.top_k_categorical_accuracy,\n",
    "                        top_10_accuracy,\n",
    "                        top_30_accuracy,\n",
    "                        top_50_accuracy,\n",
    "                        top_100_accuracy])\n",
    "    model.summary()\n",
    "    hist = model.fit([X_lidar_train,X_img_train,X_coord_train],y_train,\n",
    "            validation_data=([X_lidar_validation, X_img_validation, X_coord_validation], y_validation),\n",
    "            epochs=num_epochs,batch_size=batch_size)\n",
    "\n",
    "else:\n",
    "    if 'coord' in args.input:\n",
    "        model = coord_model\n",
    "        model.compile(loss=categorical_crossentropy,\n",
    "                            optimizer=opt,\n",
    "                            metrics=[metrics.categorical_accuracy,\n",
    "                                    metrics.top_k_categorical_accuracy,\n",
    "                                    top_50_accuracy])\n",
    "        model.summary()\n",
    "        hist = model.fit(X_coord_train,y_train, \n",
    "        validation_data=(X_coord_validation, y_validation),epochs=num_epochs,batch_size=batch_size)\n",
    "\n",
    "    elif 'img' in args.input:\n",
    "        model = img_model  \n",
    "        model.compile(loss=categorical_crossentropy,\n",
    "                    optimizer=opt,\n",
    "                    metrics=[metrics.categorical_accuracy,\n",
    "                            metrics.top_k_categorical_accuracy,\n",
    "                            top_50_accuracy])\n",
    "        model.summary()\n",
    "        hist = model.fit(X_img_train,y_train, \n",
    "        validation_data=(X_img_validation, y_validation),epochs=num_epochs,batch_size=batch_size)\n",
    "\n",
    "    else:\n",
    "        model = lidar_model\n",
    "        model.compile(loss=categorical_crossentropy,\n",
    "                    optimizer=opt,\n",
    "                    metrics=[metrics.categorical_accuracy,\n",
    "                            metrics.top_k_categorical_accuracy,\n",
    "                            top_50_accuracy])\n",
    "        model.summary()\n",
    "        hist = model.fit(X_lidar_train,y_train, \n",
    "        validation_data=(X_lidar_validation, y_validation),epochs=num_epochs,batch_size=batch_size)\n",
    "\n",
    "if args.plots:\n",
    "    import matplotlib.pyplot as plt\n",
    "\n",
    "\n",
    "    import matplotlib     \n",
    "    matplotlib.rcParams.update({'font.size': 15})\n",
    "    fileNameIdentifier = '/content/drive/MyDrive/ssp_data/baseline_data/obstacles'\n",
    "    f = open(fileNameIdentifier + '.txt','w')\n",
    "    f.write(str(history.history))\n",
    "    f.close()\n",
    "\n",
    "    acc = hist.history['top_k_categorical_accuracy']\n",
    "    val_acc = hist.history['val_top_k_categorical_accuracy']\n",
    "\n",
    "    loss = hist.history['loss']\n",
    "    val_loss = hist.history['val_loss']\n",
    "    epochs = range(1, len(acc)+1)\n",
    "    \n",
    "    plt.subplot(121)\n",
    "    plt.xlabel('Epochs')\n",
    "    plt.ylabel('Accuracy')\n",
    "    plt.plot(epochs, acc, 'b--', label='accuracy', linewidth=2)\n",
    "    plt.plot(epochs, val_acc, 'g-', label='validation accuracy',linewidth=2)\n",
    "    plt.legend()\n",
    "    plt.subplot(122)\n",
    "    plt.xlabel('Epochs')\n",
    "    plt.ylabel('Loss')\n",
    "    plt.plot(epochs, loss, 'b--', label='loss',linewidth=2)\n",
    "    plt.plot(epochs, val_loss, 'g--', label='validation loss',linewidth=2)\n",
    "    plt.legend()\n",
    "\n",
    "    plt.show()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "sMN2UUn41lxc"
   },
   "outputs": [],
   "source": [
    "!python /content/drive/MyDrive/ssp_data/baseline_data/beam_output/joint.py"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "executionInfo": {
     "elapsed": 1780990,
     "status": "ok",
     "timestamp": 1616624487777,
     "user": {
      "displayName": "Ailton Pinto de Oliveira",
      "photoUrl": "https://lh3.googleusercontent.com/a-/AOh14Ghba5Ilrbg0ZuDIpQjNURV-A8r6PgXm3WUhvzjF=s64",
      "userId": "15024272549932156605"
     },
     "user_tz": 180
    },
    "id": "zwEYs1RnHqdN",
    "outputId": "ae78814a-f875-4040-ea84-285d255e2320"
   },
   "outputs": [],
   "source": [
    "!python3 /content/drive/MyDrive/ssp_data/baseline_data/collab.py /content/drive/MyDrive/ssp_data/baseline_data/output --input img lidar coord"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "3ciybTfRWr86"
   },
   "source": [
    "loss: 6.8088 - categorical_accuracy: 0.2361 - top_k_categorical_accuracy: 0.5492 - top_10_accuracy: 0.6675 - top_30_accuracy: 1.0000 - top_50_accuracy: 1.0000 - top_100_accuracy: 1.0000\n",
    "\n",
    "categorical_accuracy: 0.1842 - top_k_categorical_accuracy: 0.5260 - top_10_accuracy: 0.6434 - top_30_accuracy: 1.0000 - top_50_accuracy: 1.0000 - top_100_accuracy: 1.0000 \n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "executionInfo": {
     "elapsed": 1718846,
     "status": "ok",
     "timestamp": 1616626968532,
     "user": {
      "displayName": "Ailton Pinto de Oliveira",
      "photoUrl": "https://lh3.googleusercontent.com/a-/AOh14Ghba5Ilrbg0ZuDIpQjNURV-A8r6PgXm3WUhvzjF=s64",
      "userId": "15024272549932156605"
     },
     "user_tz": 180
    },
    "id": "NmXmgn6eXjv1",
    "outputId": "08c2e7fe-b74d-4c2f-89e3-4a18b87a3597"
   },
   "outputs": [],
   "source": [
    "!python3 /content/drive/MyDrive/ssp_data/baseline_data/collab.py /content/drive/MyDrive/ssp_data/baseline_data/output --input img lidar coord "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "RZJaW-HPqzqr",
    "outputId": "8635b022-6914-4a93-c6b4-78cd67735a45"
   },
   "outputs": [],
   "source": [
    "!python3 /content/drive/MyDrive/ssp_data/baseline_data/collab.py /content/drive/MyDrive/ssp_data/baseline_data/output --input img lidar coord"
   ]
  }
 ],
 "metadata": {
  "accelerator": "GPU",
  "colab": {
   "authorship_tag": "ABX9TyNq/QMdnn7aPyFn7hHiZTO4",
   "mount_file_id": "11r8kQJaJBHyy4IU_c7SWwE3dAHvbRibk",
   "name": "beam_selection.ipynb",
   "provenance": []
  },
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.10"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 1
}
