{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "HZ2UfLs0_qU2"
   },
   "source": [
    "ICC Tutorial - June 14, 2021\n",
    "Tutorial 14: Machine Learning for MIMO Systems with Large Arrays\n",
    "Aldebaro Klautau (UFPA),\n",
    "Nuria Gonzalez-Prelcic (NCSU) and\n",
    "Robert W. Heath Jr. (NCSU)\n",
    "\n",
    "This script uses Raymobtime data (https://www.lasse.ufpa.br/raymobtime/) and is based on the code used for the UFPA Problem Statement in the 2020 ITU Artificial Intelligence/Machine Learning in 5G Challenge (http://ai5gchallenge.ufpa.br/).\n",
    "\n",
    "Authors: Aldebaro Klautau, Ailton Oliveira, Arthur Nascimento, Diego Gomes, Jamelly Ferreira, Walter Frazao"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "id": "M2SeKunI_gdX"
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "d:\\Programs\\Anaconda3\\envs\\python36\\lib\\site-packages\\tensorflow\\python\\framework\\dtypes.py:516: FutureWarning: Passing (type, 1) or '1type' as a synonym of type is deprecated; in a future version of numpy, it will be understood as (type, (1,)) / '(1,)type'.\n",
      "  _np_qint8 = np.dtype([(\"qint8\", np.int8, 1)])\n",
      "d:\\Programs\\Anaconda3\\envs\\python36\\lib\\site-packages\\tensorflow\\python\\framework\\dtypes.py:517: FutureWarning: Passing (type, 1) or '1type' as a synonym of type is deprecated; in a future version of numpy, it will be understood as (type, (1,)) / '(1,)type'.\n",
      "  _np_quint8 = np.dtype([(\"quint8\", np.uint8, 1)])\n",
      "d:\\Programs\\Anaconda3\\envs\\python36\\lib\\site-packages\\tensorflow\\python\\framework\\dtypes.py:518: FutureWarning: Passing (type, 1) or '1type' as a synonym of type is deprecated; in a future version of numpy, it will be understood as (type, (1,)) / '(1,)type'.\n",
      "  _np_qint16 = np.dtype([(\"qint16\", np.int16, 1)])\n",
      "d:\\Programs\\Anaconda3\\envs\\python36\\lib\\site-packages\\tensorflow\\python\\framework\\dtypes.py:519: FutureWarning: Passing (type, 1) or '1type' as a synonym of type is deprecated; in a future version of numpy, it will be understood as (type, (1,)) / '(1,)type'.\n",
      "  _np_quint16 = np.dtype([(\"quint16\", np.uint16, 1)])\n",
      "d:\\Programs\\Anaconda3\\envs\\python36\\lib\\site-packages\\tensorflow\\python\\framework\\dtypes.py:520: FutureWarning: Passing (type, 1) or '1type' as a synonym of type is deprecated; in a future version of numpy, it will be understood as (type, (1,)) / '(1,)type'.\n",
      "  _np_qint32 = np.dtype([(\"qint32\", np.int32, 1)])\n",
      "d:\\Programs\\Anaconda3\\envs\\python36\\lib\\site-packages\\tensorflow\\python\\framework\\dtypes.py:525: FutureWarning: Passing (type, 1) or '1type' as a synonym of type is deprecated; in a future version of numpy, it will be understood as (type, (1,)) / '(1,)type'.\n",
      "  np_resource = np.dtype([(\"resource\", np.ubyte, 1)])\n",
      "d:\\Programs\\Anaconda3\\envs\\python36\\lib\\site-packages\\tensorboard\\compat\\tensorflow_stub\\dtypes.py:541: FutureWarning: Passing (type, 1) or '1type' as a synonym of type is deprecated; in a future version of numpy, it will be understood as (type, (1,)) / '(1,)type'.\n",
      "  _np_qint8 = np.dtype([(\"qint8\", np.int8, 1)])\n",
      "d:\\Programs\\Anaconda3\\envs\\python36\\lib\\site-packages\\tensorboard\\compat\\tensorflow_stub\\dtypes.py:542: FutureWarning: Passing (type, 1) or '1type' as a synonym of type is deprecated; in a future version of numpy, it will be understood as (type, (1,)) / '(1,)type'.\n",
      "  _np_quint8 = np.dtype([(\"quint8\", np.uint8, 1)])\n",
      "d:\\Programs\\Anaconda3\\envs\\python36\\lib\\site-packages\\tensorboard\\compat\\tensorflow_stub\\dtypes.py:543: FutureWarning: Passing (type, 1) or '1type' as a synonym of type is deprecated; in a future version of numpy, it will be understood as (type, (1,)) / '(1,)type'.\n",
      "  _np_qint16 = np.dtype([(\"qint16\", np.int16, 1)])\n",
      "d:\\Programs\\Anaconda3\\envs\\python36\\lib\\site-packages\\tensorboard\\compat\\tensorflow_stub\\dtypes.py:544: FutureWarning: Passing (type, 1) or '1type' as a synonym of type is deprecated; in a future version of numpy, it will be understood as (type, (1,)) / '(1,)type'.\n",
      "  _np_quint16 = np.dtype([(\"quint16\", np.uint16, 1)])\n",
      "d:\\Programs\\Anaconda3\\envs\\python36\\lib\\site-packages\\tensorboard\\compat\\tensorflow_stub\\dtypes.py:545: FutureWarning: Passing (type, 1) or '1type' as a synonym of type is deprecated; in a future version of numpy, it will be understood as (type, (1,)) / '(1,)type'.\n",
      "  _np_qint32 = np.dtype([(\"qint32\", np.int32, 1)])\n",
      "d:\\Programs\\Anaconda3\\envs\\python36\\lib\\site-packages\\tensorboard\\compat\\tensorflow_stub\\dtypes.py:550: FutureWarning: Passing (type, 1) or '1type' as a synonym of type is deprecated; in a future version of numpy, it will be understood as (type, (1,)) / '(1,)type'.\n",
      "  np_resource = np.dtype([(\"resource\", np.ubyte, 1)])\n"
     ]
    }
   ],
   "source": [
    "'''\n",
    "Train a deep NN for choosing top-K beams.\n",
    "Note that you need to download the datasets and save them in the folder specified in this code. \n",
    "'''\n",
    "\n",
    "#Import modules\n",
    "import os\n",
    "import csv\n",
    "import argparse\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "import tensorflow as tf\n",
    "from tensorflow.keras import metrics\n",
    "from tensorflow.keras.models import model_from_json,Model\n",
    "from tensorflow.keras.layers import Dense,concatenate\n",
    "from tensorflow.keras.losses import categorical_crossentropy\n",
    "from tensorflow.keras.optimizers import Adadelta,Adam\n",
    "from sklearn.model_selection import train_test_split\n",
    "from ml4comm.model_handler import ModelHandler"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "id": "64sKBpO_Dz7S"
   },
   "outputs": [],
   "source": [
    "#Here you can choose a combination of sets of parameters to be used as the neural network input\n",
    "coord = False  #coordinates with the receiver position obtained from GPS\n",
    "img = False  #RGB images obtained from cameras\n",
    "lidar = True  #three-dimensional histogram obtained form LIDAR point cloud\n",
    "\n",
    "#Based on your choices above, make sure the datasets below can be found in the specific folders.\n",
    "#If running on Colab, you may use /content/\n",
    "COORDINATES_INPUT_FILE = \"./data/coord_input/coord_input.npz\"\n",
    "IMAGES_INPUT_FILE = \"./data/image_input/img_input_20.npz\"\n",
    "LIDAR_INPUT_FILE = \"./data/lidar_input/lidar_input.npz\"\n",
    "BEAM_OUTPUT_FILE = \"./data/beam_output/beams_output.npz\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "id": "yR2f0lT3BD41"
   },
   "outputs": [],
   "source": [
    "###############################################################################\n",
    "# Support functions\n",
    "###############################################################################\n",
    "\n",
    "#For description about top-k, including the explanation on how they treat ties (which can be misleading\n",
    "#if your classifier is outputting a lot of ties (e.g. all 0's will lead to high top-k)\n",
    "#https://www.tensorflow.org/api_docs/python/tf/nn/in_top_k\n",
    "#define top-k accuracy for different values of k\n",
    "def top_10_accuracy(y_true,y_pred):\n",
    "    return metrics.top_k_categorical_accuracy(y_true,y_pred,k=10)\n",
    "\n",
    "def top_30_accuracy(y_true, y_pred):\n",
    "    return metrics.top_k_categorical_accuracy(y_true, y_pred, k=30)\n",
    "\n",
    "def top_50_accuracy(y_true,y_pred):\n",
    "    return metrics.top_k_categorical_accuracy(y_true,y_pred,k=50)\n",
    "\n",
    "def top_100_accuracy(y_true, y_pred):\n",
    "    return metrics.top_k_categorical_accuracy(y_true, y_pred, k=100)\n",
    "\n",
    "#converts the combined channel gains into the label vector y\n",
    "#to be used for training the model. For instance, if a softmax\n",
    "#activation is used in the DNN output, then make y sum up to 1.\n",
    "def prepare_output_labels(original_gains):  \n",
    "    method = 1 #for using DNN output with softmax activation    \n",
    "    if method == 1:\n",
    "        thresholdBelowMax = 60 #threshold in dB for zeroing gains in log domain\n",
    "        y = log_normalize_channel_gain(original_gains,thresholdBelowMax)\n",
    "    return y\n",
    "\n",
    "#converts to log scale and make zero the values below the specified threshold\n",
    "def log_normalize_channel_gain(y,thresholdBelowMax):\n",
    "    num_gains = len(y)\n",
    "    #print('AK',num_gains)\n",
    "    for i in range(0,y.shape[0]):            \n",
    "            thisOutputs = y[i,:]\n",
    "            logOut = 20*np.log10(thisOutputs + 1e-30)\n",
    "            minValue = np.amax(logOut) - thresholdBelowMax\n",
    "            zeroedValueIndices = logOut < minValue\n",
    "            thisOutputs[zeroedValueIndices]=0\n",
    "            #normalize to sum up to 1, and enable using softmax activation\n",
    "            thisOutputs = thisOutputs / sum(thisOutputs)\n",
    "            y[i,:] = thisOutputs        \n",
    "    return y\n",
    "\n",
    "#instead of representing the pair of beam indices with two integers, use only one integer.\n",
    "#for instance, if yMatrix has a shape of (11194, 8, 32), where 8 is the number of Rx antennas\n",
    "#and 32 the number of Tx antennas, then y_output has the shape (11194, 256) because 256=8*32.\n",
    "#this way, a single index will indicate the pair of indices\n",
    "def convert_pair_to_index(yMatrix):\n",
    "    yMatrix = np.abs(yMatrix)\n",
    "    yMatrix /= np.max(yMatrix)\n",
    "    yMatrixShape = yMatrix.shape\n",
    "    num_classes = yMatrix.shape[1] * yMatrix.shape[2]\n",
    "    y = yMatrix.reshape(yMatrix.shape[0],num_classes)\n",
    "    return y, num_classes"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "###############################################################################\n",
    "# Data configuration\n",
    "###############################################################################\n",
    "tf.device('/device:GPU:0') #in case you have a GPU\n",
    "\n",
    "num_epochs = 2 #assume a rather small number just to demo things. You should try larger values\n",
    "batch_size = 32 #mini-batch size\n",
    "validation_fraction = 0.1 #fraction of all examples that will compose the validation set\n",
    "test_fraction = 0.2 #fraction of all examples that will compose the test set\n",
    "\n",
    "seed = 7 #use a fixed number if you want to reproduce the same results\n",
    "np.random.seed(seed)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "#read the datasets with input parameters\n",
    "if coord == True: \n",
    "    print(\"Reading dataset... \",COORDINATES_INPUT_FILE)\n",
    "    coord_train_cache_file = np.load(COORDINATES_INPUT_FILE)\n",
    "    X_coord = coord_train_cache_file['coordinates']    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "if img == True:\n",
    "    resizeFac = 20 # Resize Factor\n",
    "    nCh = 1 # The number of channels of the image\n",
    "    imgDim = (360,640) # Image dimensions in number of pixels\n",
    "    #method = 1\n",
    "    print(\"Reading dataset... \",IMAGES_INPUT_FILE)\n",
    "    img_train_cache_file = np.load(IMAGES_INPUT_FILE)\n",
    "    X_img = img_train_cache_file['inputs']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Reading dataset...  ./data/lidar_input/lidar_input.npz\n"
     ]
    }
   ],
   "source": [
    "if lidar == True:\n",
    "    print(\"Reading dataset... \",LIDAR_INPUT_FILE)\n",
    "    lidar_train_cache_file = np.load(LIDAR_INPUT_FILE)\n",
    "    X_lidar = lidar_train_cache_file['input']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "d51Vk9o4CzSo",
    "outputId": "e46b2848-2ca2-42ee-f9e8-fd0a5bbc2911"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Reading dataset... ./data/beam_output/beams_output.npz\n"
     ]
    }
   ],
   "source": [
    "#read the dataset with output parameters    \n",
    "print(\"Reading dataset...\", BEAM_OUTPUT_FILE)\n",
    "output_cache_file = np.load(BEAM_OUTPUT_FILE)\n",
    "yMatrix = output_cache_file['output_classification']\n",
    "y_output, num_classes = convert_pair_to_index(yMatrix)\n",
    "y = prepare_output_labels(y_output)\n",
    "\n",
    "#y_train, y_validation = train_test_split(y_output, test_size=0.2, random_state=seed, shuffle=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "#compose input and output, and also the three sets (train, test, validation)\n",
    "multimodal = [coord, img, lidar]\n",
    "num_features_categories = sum(multimodal) \n",
    "if num_features_categories == 1:\n",
    "    #single set of parameters\n",
    "    if coord:\n",
    "        X = X_coord\n",
    "    elif img:\n",
    "        X = X_img\n",
    "    elif lidar:\n",
    "        X = X_lidar\n",
    "elif num_features_categories == 3:\n",
    "    X = (X_coord, X_img, X_lidar)\n",
    "elif num_features_categories == 2:\n",
    "    if coord and lidar:\n",
    "        X = (X_coord, X_lidar)\n",
    "    elif coord and img:\n",
    "        X = (X_coord, X_img)\n",
    "    elif img and lidar:\n",
    "        X = (X_img, X_lidar)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "num_examples= 11194\n"
     ]
    }
   ],
   "source": [
    "if num_features_categories == 1:\n",
    "    num_examples = X.shape[0]\n",
    "else:\n",
    "    num_examples = X[0].shape[0]\n",
    "print('num_examples=', num_examples)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "#split examples in 3 sets: train, test, validation\n",
    "#use the indices of the examples\n",
    "indices = np.arange(num_examples)\n",
    "indices_train, indices_test_and_val = train_test_split(indices, test_size=validation_fraction+test_fraction,\n",
    "                                                       random_state=seed, shuffle=True)\n",
    "indices_validation, indices_test = train_test_split(indices_test_and_val, test_size=test_fraction/(validation_fraction+test_fraction),\n",
    "                                                       shuffle=True)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "#creates the 3 disjoint sets for the outputs\n",
    "y_train = y[indices_train]\n",
    "y_test = y[indices_test]\n",
    "y_validation = y[indices_validation]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "#creates the 3 disjoint sets for the inputs\n",
    "if num_features_categories == 1:\n",
    "    X_train = X[indices_train]\n",
    "    X_test = X[indices_test]\n",
    "    X_validation = X[indices_validation]\n",
    "elif num_features_categories == 2:\n",
    "    X_train = (X[0][indices_train], X[1][indices_train])\n",
    "    X_test = (X[0][indices_test], X[1][indices_test])\n",
    "    X_validation = (X[0][indices_validation], X[1][indices_validation])    \n",
    "elif num_features_categories == 3:\n",
    "    X_train = (X[0][indices_train], X[1][indices_train], X[2][indices_train])\n",
    "    X_test = (X[0][indices_test], X[1][indices_test], X[2][indices_test])\n",
    "    X_validation = (X[0][indices_validation], X[1][indices_validation], X[2][indices_validation])    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 945
    },
    "id": "bXtxMcdgP5EX",
    "outputId": "09f6ecf4-1ce3-45ec-9337-03358c001716"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "WARNING:tensorflow:From d:\\Programs\\Anaconda3\\envs\\python36\\lib\\site-packages\\tensorflow\\python\\ops\\init_ops.py:1251: calling VarianceScaling.__init__ (from tensorflow.python.ops.init_ops) with dtype is deprecated and will be removed in a future version.\n",
      "Instructions for updating:\n",
      "Call initializer instance with the dtype argument instead of passing it to the constructor\n",
      "Model: \"model\"\n",
      "_________________________________________________________________\n",
      "Layer (type)                 Output Shape              Param #   \n",
      "=================================================================\n",
      "input_1 (InputLayer)         [(None, 20, 200, 10)]     0         \n",
      "_________________________________________________________________\n",
      "conv2d (Conv2D)              (None, 20, 200, 10)       16910     \n",
      "_________________________________________________________________\n",
      "conv2d_1 (Conv2D)            (None, 20, 200, 10)       12110     \n",
      "_________________________________________________________________\n",
      "max_pooling2d (MaxPooling2D) (None, 6, 40, 10)         0         \n",
      "_________________________________________________________________\n",
      "dropout (Dropout)            (None, 6, 40, 10)         0         \n",
      "_________________________________________________________________\n",
      "conv2d_2 (Conv2D)            (None, 6, 40, 10)         4910      \n",
      "_________________________________________________________________\n",
      "max_pooling2d_1 (MaxPooling2 (None, 6, 20, 10)         0         \n",
      "_________________________________________________________________\n",
      "dropout_1 (Dropout)          (None, 6, 20, 10)         0         \n",
      "_________________________________________________________________\n",
      "conv2d_3 (Conv2D)            (None, 6, 20, 10)         910       \n",
      "_________________________________________________________________\n",
      "max_pooling2d_2 (MaxPooling2 (None, 6, 10, 10)         0         \n",
      "_________________________________________________________________\n",
      "dropout_2 (Dropout)          (None, 6, 10, 10)         0         \n",
      "_________________________________________________________________\n",
      "flatten (Flatten)            (None, 600)               0         \n",
      "_________________________________________________________________\n",
      "dense (Dense)                (None, 256)               153856    \n",
      "=================================================================\n",
      "Total params: 188,696\n",
      "Trainable params: 188,696\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n",
      "None\n",
      "Train on 7835 samples, validate on 1119 samples\n",
      "Epoch 1/2\n",
      "7835/7835 [==============================] - 167s 21ms/sample - loss: 4.9040 - categorical_accuracy: 0.1950 - top_k_categorical_accuracy: 0.5488 - top_10_accuracy: 0.6950 - top_30_accuracy: 0.8922 - top_50_accuracy: 0.9407 - top_100_accuracy: 0.9782 - val_loss: 4.8339 - val_categorical_accuracy: 0.2601 - val_top_k_categorical_accuracy: 0.6273 - val_top_10_accuracy: 0.7498 - val_top_30_accuracy: 0.9383 - val_top_50_accuracy: 0.9705 - val_top_100_accuracy: 0.9893\n",
      "Epoch 2/2\n",
      "4544/7835 [================>.............] - ETA: 1:06 - loss: 4.7769 - categorical_accuracy: 0.2676 - top_k_categorical_accuracy: 0.6554 - top_10_accuracy: 0.7881 - top_30_accuracy: 0.9454 - top_50_accuracy: 0.9729 - top_100_accuracy: 0.9916"
     ]
    }
   ],
   "source": [
    "##############################################################################\n",
    "# Model configuration\n",
    "##############################################################################\n",
    "plot = True # Active Plot output\n",
    "\n",
    "modelHandler = ModelHandler() #this class create some DNN models\n",
    "opt = Adam() #optimizer\n",
    "\n",
    "if coord:\n",
    "    coord_model = modelHandler.createArchitecture('coord_mlp',num_classes,X_coord.shape[1],'complete')\n",
    "if img:\n",
    "    if nCh==1:   \n",
    "        img_model = modelHandler.createArchitecture('light_image',num_classes,[X_img.shape[1],X_img.shape[2],1],'complete')\n",
    "    else:\n",
    "        img_model = modelHandler.createArchitecture('light_image',num_classes,[X_img.shape[1],X_img.shape[2],X_img.shape[3]],'complete')\n",
    "if lidar:\n",
    "    lidar_model = modelHandler.createArchitecture('lidar_simple',num_classes,[X_lidar.shape[1],X_lidar.shape[2],X_lidar.shape[3]],'complete')\n",
    "\n",
    "if num_features_categories == 2:\n",
    "    #recall order: (X_coord, X_img, X_lidar)\n",
    "    if coord and lidar:\n",
    "        combined_model = concatenate([coord_model.output,lidar_model.output])\n",
    "        z = Dense(num_classes,activation=\"relu\")(combined_model)\n",
    "        model = Model(inputs=[coord_model.input,lidar_model.input],outputs=z)\n",
    "    elif coord and img:\n",
    "        combined_model = concatenate([coord_model.output,img_model.output])\n",
    "        z = Dense(num_classes,activation=\"relu\")(combined_model)\n",
    "        model = Model(inputs=[coord_model.input,img_model.input],outputs=z)    \n",
    "    else:\n",
    "        combined_model = concatenate([img_model.output, lidar_model.output])\n",
    "        z = Dense(num_classes,activation=\"relu\")(combined_model)\n",
    "        model = Model(inputs=[img_model.input, lidar_model.input],outputs=z)\n",
    "\n",
    "elif num_features_categories == 3:\n",
    "    combined_model = concatenate([coord_model.output,img_model.output,lidar_model.output])\n",
    "    z = Dense(num_classes,activation=\"relu\")(combined_model)\n",
    "    model = Model(inputs=[coord_model.input,img_model.input,lidar_model.input],outputs=z)\n",
    "else:\n",
    "    if coord:\n",
    "        model = coord_model\n",
    "    elif img:\n",
    "        model = img_model  \n",
    "    else:\n",
    "        model = lidar_model\n",
    "        \n",
    "model.compile(loss=categorical_crossentropy,\n",
    "                    optimizer=opt,\n",
    "                    metrics=[metrics.categorical_accuracy,\n",
    "                            metrics.top_k_categorical_accuracy,\n",
    "                            top_10_accuracy,\n",
    "                            top_30_accuracy,\n",
    "                            top_50_accuracy,\n",
    "                            top_100_accuracy])\n",
    "\n",
    "print(model.summary())\n",
    "\n",
    "#train stage\n",
    "#note that Keras will properly deal with num_features_categories=1, 2 or 3.\n",
    "#for num_features_categories > 1, Keras will detect it is a tuple and feed\n",
    "#the distinct neural network inputs with the correct data\n",
    "hist = model.fit(X_train, y_train, epochs=num_epochs, batch_size=batch_size,\n",
    "                     validation_data=(X_validation, y_validation))\n",
    "\n",
    "#save training statistics\n",
    "with open('history.txt', 'w') as f: \n",
    "       f.write(str(hist.history))\n",
    "\n",
    "if plot:\n",
    "       k_beams = [1, 5, 10, 30, 50]\n",
    "       fig, ax = plt.subplots(figsize=(7,4))\n",
    "       # acurracy's\n",
    "       y = [max(hist.history['categorical_accuracy']),\n",
    "       max(hist.history['top_k_categorical_accuracy']),\n",
    "       max(hist.history['top_10_accuracy']),\n",
    "       max(hist.history['top_30_accuracy']),\n",
    "       max(hist.history['top_50_accuracy'])]\n",
    "       ax.plot(k_beams,y, 'r--s', label = 'Beam selection accuracy')\n",
    "       # original labels\n",
    "       '''ax.plot(k_beams,y_ori, 'b--s', label = 'Correct orientation-LIDAR')\n",
    "       ax.plot(k_beams,y_sori, 'k--s', label = 'Fixed oientation-LIDAR ')\n",
    "       ax.plot(k_beams,y_MM_ori, 'm--s', label = 'Correct orientation-MM')\n",
    "       ax.plot(k_beams,y_MM_sori, 'r--s', label = 'Fixed oientation-MM')'''\n",
    "       ax.set(xlabel='Top K', ylabel='Accuracy')\n",
    "       plt.xlim(right=51)\n",
    "       ax.grid()\n",
    "       plt.legend()\n",
    "       plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "owJTCe03bK08"
   },
   "source": [
    "## **Accuracy per epochs on training set**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 279
    },
    "id": "wiwCaFRsbIqE",
    "outputId": "dd017573-11ba-41fe-e5f4-d51f5ed2ba7b"
   },
   "outputs": [],
   "source": [
    "fig, ax = plt.subplots(figsize=(7,4))\n",
    "ax.plot(hist.history['categorical_accuracy'], 'b', label = 'Categorical accuracy', linewidth=2)\n",
    "ax.plot(hist.history['top_k_categorical_accuracy'], 'k--', label = 'Top 5', linewidth=2)\n",
    "ax.plot(hist.history['top_10_accuracy'], 'm', label = 'Top 10', linewidth=2)\n",
    "ax.plot(hist.history['top_30_accuracy'], 'g--', label = 'Top 30', linewidth=2)\n",
    "ax.plot(hist.history['top_50_accuracy'], 'r', label = 'Top 50', linewidth=2)\n",
    "ax.set(xlabel='Epochs', ylabel='Accuracy')\n",
    "ax.grid()\n",
    "plt.legend()\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "CPQdzsj9cHTa"
   },
   "source": [
    "## **Accuracy for k=1 on test set**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 279
    },
    "id": "_0WkXun2bjnL",
    "outputId": "bec27a82-dde7-4664-89c1-e9730bc8d8c8"
   },
   "outputs": [],
   "source": [
    "#test stage\n",
    "model_predict = model.predict(X_test)\n",
    "y_predicted_best_index = np.argmax(model_predict, axis=1)\n",
    "y_correct_best_index = np.argmax(y_test, axis=1)\n",
    "from sklearn.metrics import accuracy_score\n",
    "print('top-1 accuracy=', accuracy_score(y_correct_best_index, y_predicted_best_index))"
   ]
  }
 ],
 "metadata": {
  "colab": {
   "name": "beam_selection.ipynb",
   "provenance": []
  },
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.10"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 1
}
